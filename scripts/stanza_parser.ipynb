{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from lxml import etree\n",
    "import csv\n",
    "import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stanza.download('fr')\n",
    "\n",
    "nlp = stanza.Pipeline(lang='fr', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "#doc = nlp('Barack Obama est né à Hawaii.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_resolco_ac_norm=\"../resolco_vf/**/**/copiesNormees/ac/\"\n",
    "\n",
    "\n",
    "print(\"creation du dic pour le site transcription\"+dir_resolco_ac_norm)\n",
    "\n",
    "copies_transcript=[]\n",
    "\n",
    "files=glob.glob(dir_resolco_ac_norm+\"/*.ac\")\n",
    "cpt=0\n",
    "for file_ac in files:\n",
    "    \n",
    "    path_classe=re.sub(r'^(.*)\\/copiesNormees\\/ac\\/((EC|CO|UN)-(.+?)-[^\\/]+\\-R[0-9]+\\-V[123]\\_N).*$',r\"\\1\",file_ac)\n",
    "    idTexte=re.sub(r\"^.*\\/((EC|CO|UN)[^\\/]+\\-R[0-9]+\\-V[123]\\_N).*$\",r\"\\1\",file_ac)\n",
    "    \n",
    "    print(\"parsing POS tag stanza du fichier : \"+file_ac)\n",
    "    \n",
    "    ac=open(file_ac,'r',encoding='utf-8').read()\n",
    "    ac=re.sub('\\n','',ac)\n",
    "    doc=nlp(ac)\n",
    "    \n",
    "    #print(doc.sentences)\n",
    "    lines=[f'{word.id}\\t{word.text}\\t{word.lemma if word.lemma else \"_\"}\\t{word.upos}\\t{word.pos}\\t{word.feats if word.feats else \"_\"}\\t{word.deprel}\\t{word.head}\\t{word.start_char}\\t{word.end_char}' for sent in doc.sentences for word in sent.words]\n",
    "        \n",
    "    \n",
    "    '''OUT'''\n",
    "    rep_stanza=path_classe+\"/copiesNormees/stanza/\"\n",
    "    #if not os.path.exists(rep_stanza):\n",
    "    #   os.mkdir(rep_stanza)\n",
    "    file_out=rep_stanza+idTexte+\"_stanzapos.txt\"\n",
    "    \n",
    "    print(\"creation du fichier out : \"+file_out)\n",
    "    \n",
    "    with open(file_out, 'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(\"%s\\n\" % line)\n",
    "    \n",
    "    cpt+=1\n",
    "print(cpt)\n",
    "    \n",
    "    #print(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_aa=\"../resolco_vf/**/**/copiesAnnotees/annotations_gold/\"\n",
    "files=glob.glob(dir_aa+\"/*.aa\")\n",
    "cpt=0\n",
    "\n",
    "def getkeyStart(elem):\n",
    "    return float(elem.find('positioning/start/singlePosition').get('index'))\n",
    "\n",
    "for file_aa in files:\n",
    "    \n",
    "    path_classe=re.sub(r'^(.*)\\/copiesAnnotees\\/annotations_gold\\/((EC|CO|UN)-(.+?)-[^\\/]+\\-R[0-9]+\\-V[123]\\_N).*$',r\"\\1\",file_aa)\n",
    "    idTexte=re.sub(r\"^.*\\/((EC|CO|UN)[^\\/]+\\-R[0-9]+\\-V[123]\\_N).*$\",r\"\\1\",file_aa)\n",
    "    \n",
    "    file_stanza=path_classe+\"/copiesNormees/stanza/\"+idTexte+\"_stanzapos.txt\"\n",
    "    \n",
    "    newFile = path_classe+\"/copiesNormees/csv_stanza/\"+idTexte+'_withAnnotations.csv'\n",
    "    if not os.path.exists(path_classe+\"/copiesNormees/csv_stanza/\"):\n",
    "        os.mkdir(path_classe+\"/copiesNormees/csv_stanza/\")\n",
    "    outFile = open(newFile, mode=\"w\", encoding=\"utf-8\")\n",
    "    out=csv.writer(outFile, delimiter='\\t')\n",
    "    \n",
    "    annots=[]\n",
    "    print(\"parsing du fichier \"+file_aa)\n",
    "    \n",
    "    aa = etree.parse(file_aa)\n",
    "    root = aa.getroot()\n",
    "    units = root.findall('unit')\n",
    "    #tri des \"Units\" par leur offset de fin\n",
    "    units[:] = sorted(units, key=getkeyStart)\n",
    "    for element in units:\n",
    "        typUnit = element.find('characterisation/type')\n",
    "\n",
    "        if typUnit.text == \"phraseConsigne\":\n",
    "            if feature is not None:\t\t\n",
    "                startPosition = element.find('positioning/start/singlePosition')\n",
    "                endPosition = element.find('positioning/end/singlePosition')\n",
    "                ofsStart = int(startPosition.get('index'))\n",
    "                ofsEnd = int(endPosition.get('index'))\n",
    "                annots.append({\n",
    "                    \"start\":ofsStart,\n",
    "                    \"end\":ofsEnd,\n",
    "                    \"txt\":\"consigne\",\n",
    "                    \"typ\":\"consigne\"\n",
    "                })\n",
    "        elif typUnit.text == \"mod\":\n",
    "            feature = element.find('characterisation/featureSet/feature[@name=\"nature\"]')\n",
    "            if feature is not None:\t\t\n",
    "                startPosition = element.find('positioning/start/singlePosition')\n",
    "                endPosition = element.find('positioning/end/singlePosition')\n",
    "                ofsStart = int(startPosition.get('index'))\n",
    "                ofsEnd = int(endPosition.get('index'))\n",
    "                annots.append({\n",
    "                    \"start\":ofsStart,\n",
    "                    \"end\":ofsEnd,\n",
    "                    \"txt\":str(feature.text),\n",
    "                    \"typ\":\"modif\"\n",
    "                })\n",
    "        elif typUnit.text == \"Err_Orthographe\":\n",
    "            feature = element.find('characterisation/featureSet/feature[@name=\"version originale\"]')\n",
    "            if feature is not None:\t\t\t\t\n",
    "                startPosition = element.find('positioning/start/singlePosition')\n",
    "                endPosition = element.find('positioning/end/singlePosition')\n",
    "                ofsStart = int(startPosition.get('index'))\n",
    "                ofsEnd = int(endPosition.get('index'))\n",
    "                alt = \"\"\n",
    "                if element.find('characterisation/featureSet/feature[@name=\"correction_2\"]').text is not None: \n",
    "                    alt = \" -- alternatives : \"+element.find('characterisation/featureSet/feature[@name=\"correction_2\"]').text\n",
    "                if element.find('characterisation/featureSet/feature[@name=\"correction_3\"]').text is not None: \n",
    "                    alt = alt+\" OR \"+element.find('characterisation/featureSet/feature[@name=\"correction_3\"]').text\n",
    "                if element.find('characterisation/featureSet/feature[@name=\"correction_4\"]').text is not None: \n",
    "                    alt = alt+\" OR \"+element.find('characterisation/featureSet/feature[@name=\"correction_4\"]').text\n",
    "                annots.append({\n",
    "                    \"start\":ofsStart,\n",
    "                    \"end\":ofsEnd,\n",
    "                    \"txt\":str(feature.text)+alt,\n",
    "                    \"typ\":\"ortho\"\n",
    "                })\n",
    "        elif typUnit.text == \"maillon_Elle\":\n",
    "            feature = element.find('characterisation/featureSet/feature[@name=\"groupe\"]')\n",
    "            incertitudeD = element.find('characterisation/featureSet/feature[@name=\"incertitude sur la délimitation\"]')\n",
    "            incertitudeR = element.find('characterisation/featureSet/feature[@name=\"incertitude sur le rattachement\"]')\n",
    "            if feature is not None:\t\t\n",
    "                startPosition = element.find('positioning/start/singlePosition')\n",
    "                endPosition = element.find('positioning/end/singlePosition')\n",
    "                ofsStart = int(startPosition.get('index'))\n",
    "                ofsEnd = int(endPosition.get('index'))\n",
    "                annots.append({\n",
    "                    \"start\":ofsStart,\n",
    "                    \"end\":ofsEnd,\n",
    "                    \"txt\":\"G\"+feature.text+\"_incertD\"+incertitudeD.text+\"_incertR\"+incertitudeR.text,\n",
    "                    \"typ\":\"maillonElle\"\n",
    "                })\n",
    "        elif typUnit.text == \"maillon_Il\":\n",
    "            feature = element.find('characterisation/featureSet/feature[@name=\"groupe\"]')\n",
    "            incertitudeD = element.find('characterisation/featureSet/feature[@name=\"incertitude sur la délimitation\"]')\n",
    "            incertitudeR = element.find('characterisation/featureSet/feature[@name=\"incertitude sur le rattachement\"]')\n",
    "            if feature is not None:\t\t\n",
    "                startPosition = element.find('positioning/start/singlePosition')\n",
    "                endPosition = element.find('positioning/end/singlePosition')\n",
    "                ofsStart = int(startPosition.get('index'))\n",
    "                ofsEnd = int(endPosition.get('index'))\n",
    "                annots.append({\n",
    "                    \"start\":ofsStart,\n",
    "                    \"end\":ofsEnd,\n",
    "                    \"txt\":\"G\"+feature.text+\"_incertD\"+incertitudeD.text+\"_incertR\"+incertitudeR.text,\n",
    "                    \"typ\":\"maillonIl\"\n",
    "                })\n",
    "        elif typUnit.text == \"maillon_lesEnfants\":\n",
    "            feature = element.find('characterisation/featureSet/feature[@name=\"groupe\"]')\n",
    "            incertitudeD = element.find('characterisation/featureSet/feature[@name=\"incertitude sur la délimitation\"]')\n",
    "            incertitudeR = element.find('characterisation/featureSet/feature[@name=\"incertitude sur le rattachement\"]')\n",
    "            if feature is not None:\t\t\n",
    "                startPosition = element.find('positioning/start/singlePosition')\n",
    "                endPosition = element.find('positioning/end/singlePosition')\n",
    "                ofsStart = int(startPosition.get('index'))\n",
    "                ofsEnd = int(endPosition.get('index'))\n",
    "                membre=str(element.find('characterisation/featureSet/feature[@name=\"commentaire\"]').text)\n",
    "                if \"membre\" in membre:\n",
    "                    annots.append({\n",
    "                    \"start\":ofsStart,\n",
    "                    \"end\":ofsEnd,\n",
    "                    \"txt\":\"G\"+feature.text+\"_incertD\"+incertitudeD.text+\"_incertR\"+incertitudeR.text,\n",
    "                    \"typ\":\"maillonMembreLesEnfants\"\n",
    "                })\n",
    "                else:\n",
    "                    annots.append({\n",
    "                    \"start\":ofsStart,\n",
    "                    \"end\":ofsEnd,\n",
    "                    \"txt\":\"G\"+feature.text+\"_incertD\"+incertitudeD.text+\"_incertR\"+incertitudeR.text,\n",
    "                    \"typ\":\"maillonLesEnfants\"\n",
    "                })\n",
    "                    \n",
    "    for l in open(file_stanza,'r'):\n",
    "        l=l.rstrip(\"\\n\")\n",
    "        tal = l.split(\"\\t\")\n",
    "        if re.search(r\"^[0-9]+\",tal[0]): # si la première valeur est un nombre alors la ligne correspond à l'analyse d'un token\n",
    "\n",
    "            if re.search(r\"^[0-9]+\",tal[8]) and re.search(r\"^[0-9]+\",tal[9]): #si les ofsets sont renseignés\n",
    "                ofsStart = int(tal[8]) \n",
    "                ofsEnd = int(tal[9])\n",
    "                consigne = \"\\t_\" # variable qui indique si le token est dans une des phrases consigne\n",
    "                mod = \"\\t_\\t_\" # variable mod contient 2 valeurs indiquant le type de modification dans laquelle est inclu le token et l'ofset (pour comparer)\n",
    "                err = \"\\t_\\t_\\t_\" # variable err contient 2 valeurs séparées par une tabulation et qui sera coller à la fin de la ligne pour chaque token. La valeur 1 indique si le token est inclu dans une erreur (1)  et la valeur 2 fournit le texte original (avant normalisation orthographique)\n",
    "                elle = \"\\t_\\t_\" # variable elle contient 1 valeur indiquant si le token est inclu dans un maillon Elle. La valeur indique si c'est un groupe, s'il y a eu incertitude avec la syntaxe : (is|in)GOui_incertDOui_incertRNon. Is correspond aux token qui sont un maillon. In pour les token qui sont contenus dans un maillon.\n",
    "                il = \"\\t_\\t_\" # idem pour les maillons Il\n",
    "                lesenf = \"\\t_\\t_\" # idem pour les maillons Les Enfants\n",
    "                membre=\"\\t_\\t_\"\n",
    "                for i in range(0, len(annots)):\n",
    "                    ofset = str(annots[i][\"start\"])+\"-\"+str(annots[i][\"end\"])\n",
    "                    #print(annots[i][\"typ\"]+annots[i][\"txt\"]+ofset)\n",
    "                    #3 situations, la sortie distingue les cas où l'annotation est le token (is_maillonElle) des cas où le token est inclus dans une annotation (in_maillonElle)  (peut être utiliser le système BIO : Begin, inside, outside)\n",
    "                    if ofsStart == annots[i][\"start\"] and ofsEnd == annots[i][\"end\"]:#si le token est une annotation\n",
    "                        if annots[i][\"typ\"] == \"ortho\":\n",
    "                            err = \"\\tErr\\t\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                        elif annots[i][\"typ\"] == \"modif\":\n",
    "                            mod = \"\\tis\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                        elif annots[i][\"typ\"] == \"maillonElle\":\n",
    "                            elle = \"\\tis_\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                        elif annots[i][\"typ\"] == \"maillonIl\":\n",
    "                            il = \"\\tis_\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                        elif annots[i][\"typ\"] == \"maillonLesEnfants\":\n",
    "                            lesenf = \"\\tis_\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                        elif annots[i][\"typ\"] == \"maillonMembreLesEnfants\":\n",
    "                            membre = \"\\tis_\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "\n",
    "                    elif ofsStart >= annots[i][\"start\"] and ofsEnd <= annots[i][\"end\"]:#si le token est inclus dans une annotation\n",
    "                        if annots[i][\"typ\"] == \"consigne\":\n",
    "                            consigne = \"\\tconsigne\"\n",
    "                        elif annots[i][\"typ\"] == \"ortho\":\n",
    "                            err = \"\\tErr\\t\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                        elif annots[i][\"typ\"] == \"modif\":\n",
    "                            mod = \"\\tin_\"+annots[i][\"txt\"]+\"\\t\"+ofset\t\t\t\t\t\t\t\t\t\t\t\n",
    "                        elif annots[i][\"typ\"] == \"maillonElle\":\n",
    "                            elle = \"\\tin_\"+annots[i][\"txt\"]+\"\\t\"+ofset\t\t\t\t\t\t\t\t\n",
    "                        elif annots[i][\"typ\"] == \"maillonIl\":\n",
    "                            il = \"\\tin_\"+annots[i][\"txt\"]+\"\\t\"+ofset\t\t\t\t\t\t\t\t\n",
    "                        elif annots[i][\"typ\"] == \"maillonLesEnfants\":\n",
    "                            lesenf = \"\\tin_\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                        elif annots[i][\"typ\"] == \"maillonMembreLesEnfants\":\n",
    "                            membre = \"\\tin_\"+annots[i][\"txt\"]+\"\\t\"+ofset\t\t\t\t\t\t\t\t\n",
    "\n",
    "                    elif ofsStart <= annots[i][\"start\"] and ofsEnd >= annots[i][\"end\"]:#si le token inclut une annotation\n",
    "                            if annots[i][\"typ\"] == \"ortho\":\n",
    "                                err = \"\\tErr\\t\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                            elif annots[i][\"typ\"] == \"modif\":\n",
    "                                mod = \"\\t\"+annots[i][\"txt\"]+\"\\t\"+ofset\t\t\t\t\t\t\t\t\t\t\t\n",
    "                            elif annots[i][\"typ\"] == \"maillonElle\":\n",
    "                                elle = \"\\t\"+annots[i][\"txt\"]+\"\\t\"+ofset\t\t\t\t\t\t\t\t\n",
    "                            elif annots[i][\"typ\"] == \"maillonIl\":\n",
    "                                il = \"\\t\"+annots[i][\"txt\"]+\"\\t\"+ofset\t\t\t\t\t\t\t\t\n",
    "                            elif annots[i][\"typ\"] == \"maillonLesEnfants\":\n",
    "                                lesenf = \"\\t\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "                            elif annots[i][\"typ\"] == \"maillonMembreLesEnfants\":\n",
    "                                membre = \"\\t\"+annots[i][\"txt\"]+\"\\t\"+ofset\n",
    "\n",
    "                output=l+consigne+mod+err+elle+il+lesenf+membre\n",
    "                output=output.split(\"\\t\")\n",
    "                out.writerow(output)\n",
    "            else:\n",
    "                output=l+\"\\t_\\t_\\t_\\t_\\t_\\t \\t \\t \\t \\t \"\n",
    "                output=output.split(\"\\t\")\n",
    "                out.writerow(output)\n",
    "        elif l == \"\" :\n",
    "            out.writerow(\"\\n\")\n",
    "    annots.clear\n",
    "    print(newFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
